# å‰ç«¯å¼€å‘è€…çš„ AI Agent å…¨æ ˆå¼€å‘å­¦ä¹ è·¯çº¿ï¼ˆ2026ç‰ˆï¼‰

## ä¸€ã€å‰ç«¯å¼€å‘è€…çš„ä¼˜åŠ¿åˆ†æ

ä½œä¸ºå‰ç«¯å¼€å‘è€…ï¼Œä½ å·²ç»å…·å¤‡ä»¥ä¸‹ä¼˜åŠ¿ï¼š
- âœ… JavaScript/TypeScript æ‰å®åŸºç¡€
- âœ… ç”¨æˆ·äº¤äº’å’ŒUIè®¾è®¡ç»éªŒ
- âœ… å¼‚æ­¥ç¼–ç¨‹å’ŒçŠ¶æ€ç®¡ç†èƒ½åŠ›
- âœ… å·¥ç¨‹åŒ–æ€ç»´å’Œå·¥å…·é“¾ç»éªŒ

**éœ€è¦è¡¥å……çš„èƒ½åŠ›**ï¼š
- ğŸ”¸ åç«¯å¼€å‘ï¼ˆAPIè®¾è®¡ã€æ•°æ®åº“ã€éƒ¨ç½²ï¼‰
- ğŸ”¸ AI/LLM åŸºç¡€çŸ¥è¯†
- ğŸ”¸ Prompt Engineering
- ğŸ”¸ å‘é‡æ•°æ®åº“å’Œ RAG
- ğŸ”¸ Agent æ¶æ„è®¾è®¡

## äºŒã€æŠ€æœ¯æ ˆå­¦ä¹ æ¸…å•

### é˜¶æ®µä¸€ï¼šAI åŸºç¡€è®¤çŸ¥ï¼ˆ2-3å‘¨ï¼‰

#### 1. å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŸºç¡€
**æ ¸å¿ƒæ¦‚å¿µ**
- [ ] LLM çš„å·¥ä½œåŸç†ï¼ˆTransformeræ¶æ„åŸºç¡€äº†è§£ï¼‰
- [ ] Tokenã€ä¸Šä¸‹æ–‡çª—å£ã€æ¸©åº¦å‚æ•°
- [ ] ä¸»æµæ¨¡å‹å¯¹æ¯”ï¼ˆGPT-4ã€Claudeã€Geminiã€å›½äº§æ¨¡å‹ï¼‰
- [ ] APIè°ƒç”¨æˆæœ¬å’Œé™åˆ¶

**å®è·µä»»åŠ¡**
```javascript
// å®Œæˆç¬¬ä¸€ä¸ª LLM API è°ƒç”¨
import Anthropic from '@anthropic-ai/sdk'

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
})

const message = await client.messages.create({
  model: 'claude-4.5-sonnet-20250101',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'Hello, Claude!' }
  ]
})

console.log(message.content)
```

**å­¦ä¹ èµ„æº**
- Anthropic å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.anthropic.com
- OpenAI API æ–‡æ¡£ï¼šhttps://platform.openai.com/docs
- å´æ©è¾¾ã€Šé¢å‘å¼€å‘è€…çš„ ChatGPT Prompt Engineeringã€‹è¯¾ç¨‹

---

#### 2. Prompt Engineeringï¼ˆæç¤ºè¯å·¥ç¨‹ï¼‰
**æ ¸å¿ƒæŠ€èƒ½**
- [ ] é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰å’Œå°‘æ ·æœ¬ï¼ˆFew-shotï¼‰æç¤º
- [ ] æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æç¤º
- [ ] è§’è‰²è®¾å®šå’Œç³»ç»Ÿæç¤ºè¯
- [ ] ç»“æ„åŒ–è¾“å‡ºï¼ˆJSONæ¨¡å¼ï¼‰
- [ ] æç¤ºè¯ä¼˜åŒ–æŠ€å·§

**å®è·µä»»åŠ¡**
```typescript
// å®ç°ä¸€ä¸ªæ™ºèƒ½çš„ä»»åŠ¡åˆ†è§£å™¨
interface Task {
  title: string
  subtasks: string[]
  priority: 'high' | 'medium' | 'low'
}

async function decomposeTask(userInput: string): Promise<Task> {
  const prompt = `
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®ç®¡ç†åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·çš„ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡ã€‚

ç”¨æˆ·ä»»åŠ¡ï¼š${userInput}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
  "title": "ä»»åŠ¡æ ‡é¢˜",
  "subtasks": ["å­ä»»åŠ¡1", "å­ä»»åŠ¡2"],
  "priority": "high/medium/low"
}
`

  const response = await callLLM(prompt)
  return JSON.parse(response)
}
```

**å­¦ä¹ èµ„æº**
- Learn Promptingï¼šhttps://learnprompting.org
- Anthropic Prompt Engineering Guide
- å®è·µï¼šåœ¨ playground ä¸­å°è¯•ä¸åŒçš„æç¤ºç­–ç•¥

---

### é˜¶æ®µäºŒï¼šå…¨æ ˆæŠ€æœ¯è¡¥å……ï¼ˆ3-4å‘¨ï¼‰

#### 3. Node.js åç«¯å¼€å‘
**æ ¸å¿ƒæŠ€èƒ½**
- [ ] Express / Fastify / Hono æ¡†æ¶
- [ ] RESTful API è®¾è®¡
- [ ] ä¸­é—´ä»¶å’Œé”™è¯¯å¤„ç†
- [ ] è®¤è¯æˆæƒï¼ˆJWTï¼‰
- [ ] WebSocket å®æ—¶é€šä¿¡

**å®è·µé¡¹ç›®**
```typescript
// åˆ›å»ºä¸€ä¸ª AI èŠå¤© API
import express from 'express'
import Anthropic from '@anthropic-ai/sdk'

const app = express()
const client = new Anthropic()

app.post('/api/chat', async (req, res) => {
  const { messages } = req.body

  const stream = await client.messages.stream({
    model: 'claude-4.5-sonnet-20250101',
    max_tokens: 1024,
    messages
  })

  res.setHeader('Content-Type', 'text/event-stream')

  for await (const chunk of stream) {
    if (chunk.type === 'content_block_delta') {
      res.write(`data: ${JSON.stringify(chunk.delta)}\n\n`)
    }
  }

  res.end()
})

app.listen(3000)
```

**å­¦ä¹ èµ„æº**
- Node.js å®˜æ–¹æ–‡æ¡£
- Express.js Guide
- ã€Šæ·±å…¥æµ…å‡º Node.jsã€‹

---

#### 4. æ•°æ®åº“æŠ€æœ¯
**æ ¸å¿ƒæŠ€èƒ½**
- [ ] **å…³ç³»å‹æ•°æ®åº“**ï¼šPostgreSQL / MySQL
  - SQL åŸºç¡€æ“ä½œ
  - ORM ä½¿ç”¨ï¼ˆPrisma / TypeORMï¼‰
  - æ•°æ®å»ºæ¨¡

- [ ] **å‘é‡æ•°æ®åº“**ï¼šPinecone / Weaviate / Chroma
  - å‘é‡åµŒå…¥ï¼ˆEmbeddingsï¼‰æ¦‚å¿µ
  - ç›¸ä¼¼åº¦æœç´¢
  - RAG åº”ç”¨

- [ ] **ç¼“å­˜**ï¼šRedis
  - ç¼“å­˜ç­–ç•¥
  - ä¼šè¯å­˜å‚¨

**å®è·µé¡¹ç›®**
```typescript
// ä½¿ç”¨ Prisma è®¾è®¡ AI å¯¹è¯æ•°æ®æ¨¡å‹
// schema.prisma
model Conversation {
  id        String   @id @default(uuid())
  userId    String
  title     String
  createdAt DateTime @default(now())
  messages  Message[]
}

model Message {
  id             String       @id @default(uuid())
  conversationId String
  conversation   Conversation @relation(fields: [conversationId], references: [id])
  role           String       // 'user' | 'assistant'
  content        String       @db.Text
  tokens         Int?
  createdAt      DateTime     @default(now())
}

// å‘é‡æœç´¢ç¤ºä¾‹
import { Pinecone } from '@pinecone-database/pinecone'

const pc = new Pinecone({ apiKey: 'your-api-key' })
const index = pc.index('knowledge-base')

// å­˜å‚¨çŸ¥è¯†
await index.upsert([{
  id: 'doc1',
  values: embedding, // ä» OpenAI Embeddings API è·å–
  metadata: { text: 'åŸå§‹æ–‡æœ¬', source: 'doc.pdf' }
}])

// æ£€ç´¢ç›¸å…³çŸ¥è¯†
const results = await index.query({
  vector: queryEmbedding,
  topK: 3,
  includeMetadata: true
})
```

**å­¦ä¹ èµ„æº**
- Prisma å®˜æ–¹æ–‡æ¡£
- PostgreSQL æ•™ç¨‹
- Pinecone å¿«é€Ÿå¼€å§‹æŒ‡å—

---

### é˜¶æ®µä¸‰ï¼šAI Agent æ ¸å¿ƒæŠ€æœ¯ï¼ˆ4-5å‘¨ï¼‰

#### 5. RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
**æ ¸å¿ƒæ¦‚å¿µ**
- [ ] æ–‡æ¡£å¤„ç†å’Œåˆ†å—ï¼ˆChunkingï¼‰
- [ ] åµŒå…¥å‘é‡ç”Ÿæˆï¼ˆEmbeddingsï¼‰
- [ ] ç›¸ä¼¼åº¦æ£€ç´¢
- [ ] ä¸Šä¸‹æ–‡æ³¨å…¥
- [ ] RAG ä¼˜åŒ–ç­–ç•¥

**æŠ€æœ¯æ ˆ**
- LangChain / LlamaIndexï¼ˆå¯é€‰ï¼‰
- OpenAI Embeddings API / Cohere Embed
- å‘é‡æ•°æ®åº“

**å®è·µé¡¹ç›®ï¼šæ„å»ºçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ**
```typescript
// rag-service.ts
import { OpenAI } from 'openai'
import { Pinecone } from '@pinecone-database/pinecone'

class RAGService {
  private openai: OpenAI
  private pinecone: Pinecone

  constructor() {
    this.openai = new OpenAI()
    this.pinecone = new Pinecone()
  }

  // 1. æ–‡æ¡£å¤„ç†å’Œå­˜å‚¨
  async ingestDocument(text: string, metadata: any) {
    // åˆ†å—
    const chunks = this.chunkText(text, 500)

    // ç”ŸæˆåµŒå…¥å‘é‡
    const embeddings = await Promise.all(
      chunks.map(chunk => this.getEmbedding(chunk))
    )

    // å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    const index = this.pinecone.index('docs')
    await index.upsert(
      chunks.map((chunk, i) => ({
        id: `${metadata.docId}_${i}`,
        values: embeddings[i],
        metadata: { text: chunk, ...metadata }
      }))
    )
  }

  // 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
  async retrieveContext(query: string, topK = 3) {
    const queryEmbedding = await this.getEmbedding(query)
    const index = this.pinecone.index('docs')

    const results = await index.query({
      vector: queryEmbedding,
      topK,
      includeMetadata: true
    })

    return results.matches.map(m => m.metadata.text)
  }

  // 3. ç”Ÿæˆå›ç­”
  async answer(question: string) {
    // æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
    const context = await this.retrieveContext(question)

    // æ„å»ºæç¤ºè¯
    const prompt = `
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
${context.join('\n\n')}

é—®é¢˜ï¼š${question}

è¯·åŸºäºä¸Šä¸‹æ–‡å‡†ç¡®å›ç­”ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
`

    // è°ƒç”¨ LLM
    const response = await this.openai.chat.completions.create({
      model: 'gpt-4-turbo',
      messages: [{ role: 'user', content: prompt }]
    })

    return response.choices[0].message.content
  }

  private async getEmbedding(text: string): Promise<number[]> {
    const response = await this.openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: text
    })
    return response.data[0].embedding
  }

  private chunkText(text: string, chunkSize: number): string[] {
    // ç®€å•çš„åˆ†å—å®ç°
    const words = text.split(' ')
    const chunks: string[] = []

    for (let i = 0; i < words.length; i += chunkSize) {
      chunks.push(words.slice(i, i + chunkSize).join(' '))
    }

    return chunks
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const rag = new RAGService()

// å¯¼å…¥çŸ¥è¯†
await rag.ingestDocument(documentText, { docId: 'manual-v1' })

// é—®ç­”
const answer = await rag.answer('å¦‚ä½•é…ç½®ç¯å¢ƒå˜é‡ï¼Ÿ')
console.log(answer)
```

**å­¦ä¹ èµ„æº**
- LangChain æ–‡æ¡£ï¼šhttps://js.langchain.com
- RAG è®ºæ–‡å’Œæœ€ä½³å®è·µ
- Pinecone Learning Center

---

#### 6. Function Calling / Tool Use
**æ ¸å¿ƒæ¦‚å¿µ**
- [ ] å·¥å…·å®šä¹‰å’Œæ³¨å†Œ
- [ ] å·¥å…·è°ƒç”¨æµç¨‹
- [ ] å¤šè½®å¯¹è¯ç®¡ç†
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•

**å®è·µé¡¹ç›®ï¼šå¤©æ°”æŸ¥è¯¢ Agent**
```typescript
// tools.ts
interface Tool {
  name: string
  description: string
  parameters: any
  execute: (args: any) => Promise<any>
}

const tools: Tool[] = [
  {
    name: 'get_weather',
    description: 'è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯',
    parameters: {
      type: 'object',
      properties: {
        city: {
          type: 'string',
          description: 'åŸå¸‚åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·'
        }
      },
      required: ['city']
    },
    execute: async ({ city }) => {
      // è°ƒç”¨å¤©æ°” API
      const response = await fetch(`https://api.weather.com/${city}`)
      return response.json()
    }
  },
  {
    name: 'search_web',
    description: 'åœ¨äº’è”ç½‘ä¸Šæœç´¢ä¿¡æ¯',
    parameters: {
      type: 'object',
      properties: {
        query: { type: 'string', description: 'æœç´¢å…³é”®è¯' }
      },
      required: ['query']
    },
    execute: async ({ query }) => {
      // è°ƒç”¨æœç´¢ API
      return await searchWeb(query)
    }
  }
]

// agent.ts - ä½¿ç”¨ Anthropic Tool Use
import Anthropic from '@anthropic-ai/sdk'

class Agent {
  private client: Anthropic

  constructor() {
    this.client = new Anthropic()
  }

  async chat(userMessage: string) {
    const messages = [{ role: 'user', content: userMessage }]

    while (true) {
      const response = await this.client.messages.create({
        model: 'claude-4.5-sonnet-20250101',
        max_tokens: 1024,
        tools: tools.map(t => ({
          name: t.name,
          description: t.description,
          input_schema: t.parameters
        })),
        messages
      })

      // æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
      const toolUse = response.content.find(
        block => block.type === 'tool_use'
      )

      if (!toolUse) {
        // è¿”å›æœ€ç»ˆç­”æ¡ˆ
        return response.content.find(
          block => block.type === 'text'
        )?.text
      }

      // æ‰§è¡Œå·¥å…·
      const tool = tools.find(t => t.name === toolUse.name)
      const result = await tool.execute(toolUse.input)

      // å°†å·¥å…·ç»“æœè¿”å›ç»™æ¨¡å‹
      messages.push({
        role: 'assistant',
        content: response.content
      })
      messages.push({
        role: 'user',
        content: [{
          type: 'tool_result',
          tool_use_id: toolUse.id,
          content: JSON.stringify(result)
        }]
      })

      // ç»§ç»­å¯¹è¯å¾ªç¯
    }
  }
}

// ä½¿ç”¨
const agent = new Agent()
const answer = await agent.chat('åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ')
console.log(answer)
```

**å­¦ä¹ èµ„æº**
- Anthropic Tool Use æ–‡æ¡£
- OpenAI Function Calling æŒ‡å—
- å®æˆ˜ï¼šæ„å»ºå¤šå·¥å…·åä½œçš„ Agent

---

#### 7. Agent æ¶æ„è®¾è®¡
**æ ¸å¿ƒæ¨¡å¼**
- [ ] **ReAct æ¨¡å¼**ï¼ˆReasoning + Actingï¼‰
  - æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ æ€è€ƒ...

- [ ] **Plan-and-Execute æ¨¡å¼**
  - åˆ¶å®šè®¡åˆ’ â†’ æ‰§è¡Œæ­¥éª¤ â†’ éªŒè¯ç»“æœ

- [ ] **Multi-Agent åä½œ**
  - è§’è‰²åˆ†å·¥ï¼ˆç ”ç©¶å‘˜ã€ç¼–ç å‘˜ã€å®¡æŸ¥å‘˜ï¼‰
  - ä»»åŠ¡åˆ†é…å’Œç»“æœæ±‡æ€»

**å®è·µé¡¹ç›®ï¼šä»£ç ç”Ÿæˆ Agent**
```typescript
// code-agent.ts
interface AgentStep {
  thought: string
  action: string
  observation: string
}

class CodeGenerationAgent {
  private history: AgentStep[] = []

  async generate(requirement: string) {
    // 1. è§„åˆ’é˜¶æ®µ
    const plan = await this.planSteps(requirement)
    console.log('æ‰§è¡Œè®¡åˆ’ï¼š', plan)

    // 2. æ‰§è¡Œé˜¶æ®µ
    for (const step of plan.steps) {
      const result = await this.executeStep(step)
      this.history.push(result)
    }

    // 3. éªŒè¯é˜¶æ®µ
    const validation = await this.validate()

    if (!validation.passed) {
      // ä¿®å¤é—®é¢˜
      await this.fix(validation.issues)
    }

    return this.getFinalCode()
  }

  private async planSteps(requirement: string) {
    const prompt = `
ä½œä¸ºä¸€ä¸ªä»£ç ç”Ÿæˆä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹éœ€æ±‚åˆ¶å®šå®ç°è®¡åˆ’ï¼š

éœ€æ±‚ï¼š${requirement}

è¯·åˆ†è§£ä¸ºå…·ä½“çš„æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½è¦æ˜ç¡®ã€‚
è¿”å›JSONæ ¼å¼ï¼š
{
  "steps": [
    {"step": 1, "description": "...", "type": "research|code|test"}
  ]
}
`
    const response = await callLLM(prompt)
    return JSON.parse(response)
  }

  private async executeStep(step: any): Promise<AgentStep> {
    const thought = `æ‰§è¡Œæ­¥éª¤ ${step.step}: ${step.description}`

    let action = ''
    let observation = ''

    switch (step.type) {
      case 'research':
        action = 'ç ”ç©¶ç›¸å…³æŠ€æœ¯æ–‡æ¡£'
        observation = await this.research(step.description)
        break

      case 'code':
        action = 'ç”Ÿæˆä»£ç '
        observation = await this.generateCode(step.description)
        break

      case 'test':
        action = 'è¿è¡Œæµ‹è¯•'
        observation = await this.runTests()
        break
    }

    return { thought, action, observation }
  }

  private async validate(): Promise<{passed: boolean, issues: string[]}> {
    // ä½¿ç”¨ LLM æ£€æŸ¥ä»£ç è´¨é‡
    const code = this.getFinalCode()
    const prompt = `
è¯·æ£€æŸ¥ä»¥ä¸‹ä»£ç çš„è´¨é‡ï¼š

${code}

æ£€æŸ¥é¡¹ï¼š
1. è¯­æ³•æ­£ç¡®æ€§
2. é€»è¾‘å®Œæ•´æ€§
3. è¾¹ç•Œæƒ…å†µå¤„ç†
4. ä»£ç è§„èŒƒ

è¿”å›JSON: {"passed": boolean, "issues": []}
`
    const result = await callLLM(prompt)
    return JSON.parse(result)
  }

  // ... å…¶ä»–æ–¹æ³•
}
```

**å­¦ä¹ èµ„æº**
- ReAct è®ºæ–‡ï¼šhttps://arxiv.org/abs/2210.03629
- AutoGPT æºç åˆ†æ
- LangChain Agents æ–‡æ¡£

---

### é˜¶æ®µå››ï¼šå‰ç«¯é›†æˆä¸å®æˆ˜ï¼ˆ3-4å‘¨ï¼‰

#### 8. AI å‰ç«¯äº¤äº’è®¾è®¡
**æ ¸å¿ƒæŠ€èƒ½**
- [ ] æµå¼å“åº”å±•ç¤ºï¼ˆSSE / WebSocketï¼‰
- [ ] Markdown æ¸²æŸ“å’Œä»£ç é«˜äº®
- [ ] æ€ç»´é“¾å¯è§†åŒ–
- [ ] å®æ—¶çŠ¶æ€åé¦ˆ
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•

**å®è·µï¼šæ„å»º AI èŠå¤©ç•Œé¢**
```vue
<!-- ChatInterface.vue -->
<template>
  <div class="chat-container">
    <!-- æ¶ˆæ¯åˆ—è¡¨ -->
    <div class="messages" ref="messagesRef">
      <div
        v-for="msg in messages"
        :key="msg.id"
        :class="['message', msg.role]"
      >
        <div v-if="msg.role === 'assistant'" class="markdown-body">
          <MarkdownRenderer :content="msg.content" />
        </div>
        <div v-else>{{ msg.content }}</div>

        <!-- æ€ç»´è¿‡ç¨‹å±•ç¤º -->
        <div v-if="msg.thoughts" class="thoughts">
          <details>
            <summary>æ€ç»´è¿‡ç¨‹</summary>
            <div v-for="step in msg.thoughts" :key="step.id">
              <strong>{{ step.action }}</strong>
              <p>{{ step.observation }}</p>
            </div>
          </details>
        </div>
      </div>

      <!-- åŠ è½½çŠ¶æ€ -->
      <div v-if="isLoading" class="loading">
        <span class="typing-indicator"></span>
        <span>AI æ­£åœ¨æ€è€ƒ...</span>
      </div>
    </div>

    <!-- è¾“å…¥æ¡† -->
    <div class="input-area">
      <textarea
        v-model="userInput"
        @keydown.enter.prevent="sendMessage"
        placeholder="è¾“å…¥æ¶ˆæ¯..."
      />
      <button @click="sendMessage" :disabled="isLoading">
        å‘é€
      </button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, nextTick } from 'vue'
import MarkdownRenderer from './MarkdownRenderer.vue'

interface Message {
  id: string
  role: 'user' | 'assistant'
  content: string
  thoughts?: Array<{ action: string, observation: string }>
}

const messages = ref<Message[]>([])
const userInput = ref('')
const isLoading = ref(false)
const messagesRef = ref<HTMLElement>()

// å‘é€æ¶ˆæ¯ï¼ˆæ”¯æŒæµå¼å“åº”ï¼‰
async function sendMessage() {
  if (!userInput.value.trim() || isLoading.value) return

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  messages.value.push({
    id: Date.now().toString(),
    role: 'user',
    content: userInput.value
  })

  const userMessage = userInput.value
  userInput.value = ''
  isLoading.value = true

  // åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆæµå¼æ›´æ–°ï¼‰
  const assistantMsg: Message = {
    id: (Date.now() + 1).toString(),
    role: 'assistant',
    content: '',
    thoughts: []
  }
  messages.value.push(assistantMsg)

  try {
    // ä½¿ç”¨ SSE æ¥æ”¶æµå¼å“åº”
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        message: userMessage,
        history: messages.value.slice(0, -1)
      })
    })

    const reader = response.body?.getReader()
    const decoder = new TextDecoder()

    while (true) {
      const { done, value } = await reader!.read()
      if (done) break

      const chunk = decoder.decode(value)
      const lines = chunk.split('\n')

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6))

          if (data.type === 'content') {
            assistantMsg.content += data.text
          } else if (data.type === 'thought') {
            assistantMsg.thoughts?.push(data.step)
          }

          // è‡ªåŠ¨æ»šåŠ¨
          await nextTick()
          scrollToBottom()
        }
      }
    }
  } catch (error) {
    console.error('å‘é€å¤±è´¥ï¼š', error)
    assistantMsg.content = 'æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚'
  } finally {
    isLoading.value = false
  }
}

function scrollToBottom() {
  if (messagesRef.value) {
    messagesRef.value.scrollTop = messagesRef.value.scrollHeight
  }
}
</script>

<style scoped>
.chat-container {
  display: flex;
  flex-direction: column;
  height: 100vh;
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 20px;
}

.message {
  margin-bottom: 16px;
  padding: 12px;
  border-radius: 8px;
}

.message.user {
  background: #e3f2fd;
  margin-left: 20%;
}

.message.assistant {
  background: #f5f5f5;
  margin-right: 20%;
}

.thoughts {
  margin-top: 8px;
  padding: 8px;
  background: rgba(0,0,0,0.05);
  border-radius: 4px;
  font-size: 12px;
}

.typing-indicator {
  /* æ‰“å­—åŠ¨ç”» */
  display: inline-block;
  width: 8px;
  height: 8px;
  background: #666;
  border-radius: 50%;
  animation: typing 1s infinite;
}

@keyframes typing {
  0%, 100% { opacity: 0.3; }
  50% { opacity: 1; }
}

.input-area {
  display: flex;
  padding: 16px;
  border-top: 1px solid #ddd;
  gap: 8px;
}

textarea {
  flex: 1;
  padding: 12px;
  border: 1px solid #ddd;
  border-radius: 4px;
  resize: none;
  font-size: 14px;
}

button {
  padding: 12px 24px;
  background: #1976d2;
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
}

button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}
</style>
```

**å­¦ä¹ èµ„æº**
- SSEï¼ˆServer-Sent Eventsï¼‰è§„èŒƒ
- Vercel AI SDKï¼ˆç®€åŒ–æµå¼å“åº”ï¼‰
- ä¼˜ç§€çš„ AI äº§å“äº¤äº’åˆ†æï¼ˆChatGPTã€Claudeã€Cursorï¼‰

---

#### 9. æ€§èƒ½ä¼˜åŒ–
**æ ¸å¿ƒæŠ€æœ¯**
- [ ] è¯·æ±‚ç¼“å­˜ç­–ç•¥
- [ ] å“åº”æµå¼ä¼ è¾“
- [ ] Token ç”¨é‡ä¼˜åŒ–
- [ ] å¹¶å‘æ§åˆ¶å’Œé™æµ
- [ ] è¾¹ç¼˜è®¡ç®—éƒ¨ç½²

**å®è·µä»£ç **
```typescript
// cache-service.ts
import Redis from 'ioredis'

class LLMCacheService {
  private redis: Redis

  constructor() {
    this.redis = new Redis()
  }

  // è¯­ä¹‰ç¼“å­˜ï¼šç›¸ä¼¼é—®é¢˜å¤ç”¨ç­”æ¡ˆ
  async getCachedResponse(prompt: string, threshold = 0.95) {
    const embedding = await this.getEmbedding(prompt)

    // åœ¨ Redis ä¸­æœç´¢ç›¸ä¼¼çš„ prompt
    const similar = await this.findSimilar(embedding, threshold)

    if (similar) {
      console.log('ç¼“å­˜å‘½ä¸­ï¼')
      return similar.response
    }

    return null
  }

  async setCachedResponse(prompt: string, response: string) {
    const embedding = await this.getEmbedding(prompt)
    await this.redis.set(
      `cache:${prompt}`,
      JSON.stringify({ embedding, response }),
      'EX',
      3600 // 1å°æ—¶è¿‡æœŸ
    )
  }

  // Token é¢„ç®—ç®¡ç†
  estimateTokens(text: string): number {
    // ç®€å•ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦
    return Math.ceil(text.length / 4)
  }

  async callWithBudget(
    prompt: string,
    maxTokens: number
  ): Promise<string> {
    const estimatedInput = this.estimateTokens(prompt)

    if (estimatedInput > maxTokens * 0.7) {
      // å¦‚æœè¾“å…¥å¤ªé•¿ï¼Œè¿›è¡Œå‹ç¼©
      prompt = await this.compressPrompt(prompt)
    }

    const response = await callLLM(prompt, {
      max_tokens: maxTokens - estimatedInput
    })

    return response
  }
}
```

---

### é˜¶æ®µäº”ï¼šéƒ¨ç½²ä¸ç›‘æ§ï¼ˆ2å‘¨ï¼‰

#### 10. éƒ¨ç½²æ–¹æ¡ˆ
**æŠ€æœ¯æ ˆ**
- [ ] **åç«¯éƒ¨ç½²**
  - Docker å®¹å™¨åŒ–
  - Kubernetesï¼ˆå¯é€‰ï¼‰
  - Serverlessï¼ˆVercelã€Cloudflare Workersï¼‰

- [ ] **æ•°æ®åº“**
  - PostgreSQLï¼ˆSupabaseã€Railwayï¼‰
  - Redisï¼ˆUpstashï¼‰
  - å‘é‡æ•°æ®åº“ï¼ˆPinecone äº‘æœåŠ¡ï¼‰

- [ ] **å‰ç«¯éƒ¨ç½²**
  - Vercel / Netlify
  - CDN åŠ é€Ÿ

**å®è·µï¼šDockerfile ç¤ºä¾‹**
```dockerfile
# Dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --production

COPY . .

RUN npm run build

EXPOSE 3000

CMD ["npm", "start"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/mydb
      - REDIS_URL=redis://redis:6379
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine

volumes:
  postgres_data:
```

---

#### 11. ç›‘æ§ä¸æ—¥å¿—
**æ ¸å¿ƒæŒ‡æ ‡**
- [ ] API è°ƒç”¨æ¬¡æ•°å’Œæˆæœ¬
- [ ] å“åº”æ—¶é—´
- [ ] é”™è¯¯ç‡
- [ ] Token ä½¿ç”¨é‡
- [ ] ç”¨æˆ·æ»¡æ„åº¦

**å®è·µå·¥å…·**
```typescript
// monitoring.ts
import { Anthropic } from '@anthropic-ai/sdk'

class MonitoredLLMClient {
  private client: Anthropic
  private metrics: Map<string, any>

  constructor() {
    this.client = new Anthropic()
    this.metrics = new Map()
  }

  async call(params: any) {
    const startTime = Date.now()
    let tokens = 0
    let error = null

    try {
      const response = await this.client.messages.create(params)

      tokens = response.usage.input_tokens + response.usage.output_tokens

      return response
    } catch (e) {
      error = e
      throw e
    } finally {
      // è®°å½•æŒ‡æ ‡
      this.recordMetrics({
        duration: Date.now() - startTime,
        tokens,
        model: params.model,
        error: error?.message,
        timestamp: new Date()
      })
    }
  }

  private recordMetrics(data: any) {
    // å‘é€åˆ°ç›‘æ§å¹³å°ï¼ˆå¦‚ Prometheusã€Datadogï¼‰
    console.log('[Metrics]', data)

    // æˆ–å­˜å‚¨åˆ°æ•°æ®åº“ç”¨äºåˆ†æ
    // await db.metrics.create({ data })
  }

  getStatistics(timeRange: string) {
    // è¿”å›ç»Ÿè®¡æ•°æ®
    return {
      totalCalls: 1000,
      totalTokens: 500000,
      averageLatency: 1200,
      errorRate: 0.02,
      estimatedCost: 25.5 // USD
    }
  }
}
```

**æ¨èå·¥å…·**
- Sentryï¼ˆé”™è¯¯è¿½è¸ªï¼‰
- Prometheus + Grafanaï¼ˆæŒ‡æ ‡ç›‘æ§ï¼‰
- LangSmith / Heliconeï¼ˆLLM ä¸“ç”¨ç›‘æ§ï¼‰

---

## ä¸‰ã€åˆ†é˜¶æ®µå­¦ä¹ è®¡åˆ’ï¼ˆ16-18å‘¨ï¼‰

### ç¬¬ 1-3 å‘¨ï¼šAI åŸºç¡€
**ç›®æ ‡**ï¼šç†è§£ LLM å·¥ä½œåŸç†ï¼ŒæŒæ¡ Prompt Engineering

**ä»»åŠ¡æ¸…å•**
- [ ] æ³¨å†Œå¹¶ç†Ÿæ‚‰ Anthropic / OpenAI API
- [ ] å®Œæˆ 50 ä¸ªä¸åŒåœºæ™¯çš„ prompt ç»ƒä¹ 
- [ ] é˜…è¯»ã€ŠPrompt Engineering Guideã€‹
- [ ] æ„å»ºç¬¬ä¸€ä¸ªç®€å•çš„ AI å¯¹è¯åº”ç”¨

**é¡¹ç›®**ï¼šAI åŠ©æ‰‹èŠå¤©æœºå™¨äººï¼ˆçº¯å‰ç«¯ + APIï¼‰

---

### ç¬¬ 4-7 å‘¨ï¼šå…¨æ ˆåŸºç¡€
**ç›®æ ‡**ï¼šè¡¥å……åç«¯å¼€å‘èƒ½åŠ›ï¼ŒæŒæ¡æ•°æ®åº“

**ä»»åŠ¡æ¸…å•**
- [ ] å­¦ä¹  Node.js + Expressï¼Œå®Œæˆ 5 ä¸ª API é¡¹ç›®
- [ ] æŒæ¡ PostgreSQLï¼Œè®¾è®¡ 3 ä¸ªæ•°æ®æ¨¡å‹
- [ ] å­¦ä¹  Prisma ORM
- [ ] äº†è§£å‘é‡æ•°æ®åº“æ¦‚å¿µï¼Œæ³¨å†Œ Pinecone

**é¡¹ç›®**ï¼šå¸¦ç”¨æˆ·ç³»ç»Ÿå’Œå†å²è®°å½•çš„ AI èŠå¤©åº”ç”¨

---

### ç¬¬ 8-12 å‘¨ï¼šAI Agent æ ¸å¿ƒ
**ç›®æ ‡**ï¼šæŒæ¡ RAGã€Function Callingã€Agent æ¶æ„

**ä»»åŠ¡æ¸…å•**
- [ ] å®ç°å®Œæ•´çš„ RAG ç³»ç»Ÿ
- [ ] åˆ›å»º 5 ä¸ªä»¥ä¸Šçš„ Toolï¼Œå®ç° Function Calling
- [ ] å­¦ä¹  ReAct æ¨¡å¼ï¼Œå®ç°ä¸€ä¸ªè§„åˆ’å‹ Agent
- [ ] ç ”ç©¶ LangChain / LlamaIndexï¼ˆå¯é€‰ï¼‰

**é¡¹ç›®**ï¼š
1. æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆRAGï¼‰
2. å¤šåŠŸèƒ½ AI åŠ©æ‰‹ï¼ˆTool Useï¼‰
3. ä»£ç ç”Ÿæˆ Agentï¼ˆReActï¼‰

---

### ç¬¬ 13-16 å‘¨ï¼šå®æˆ˜é¡¹ç›®
**ç›®æ ‡**ï¼šå®Œæˆç«¯åˆ°ç«¯çš„ AI Agent åº”ç”¨

**ä»»åŠ¡æ¸…å•**
- [ ] è®¾è®¡äº§å“åŸå‹
- [ ] å®ç°å‰åç«¯å®Œæ•´åŠŸèƒ½
- [ ] ä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- [ ] æ·»åŠ ç›‘æ§å’Œæ—¥å¿—

**é¡¹ç›®é€‰æ‹©ï¼ˆé€‰ä¸€ä¸ªæ·±å…¥åšï¼‰**
1. **AI é¢è¯•å®˜**ï¼ˆå°±æ˜¯ä½ å½“å‰çš„é¡¹ç›®ï¼ï¼‰
2. **AI ä»£ç å®¡æŸ¥åŠ©æ‰‹**
3. **æ™ºèƒ½å®¢æœç³»ç»Ÿ**
4. **ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹**

---

### ç¬¬ 17-18 å‘¨ï¼šè¿›é˜¶ä¸ä¼˜åŒ–
**ç›®æ ‡**ï¼šæ€§èƒ½ä¼˜åŒ–ã€æˆæœ¬æ§åˆ¶ã€äº§å“æ‰“ç£¨

**ä»»åŠ¡æ¸…å•**
- [ ] å®ç°è¯­ä¹‰ç¼“å­˜
- [ ] Token ç”¨é‡ä¼˜åŒ–
- [ ] æ·»åŠ  A/B æµ‹è¯•
- [ ] æ”¶é›†ç”¨æˆ·åé¦ˆï¼Œè¿­ä»£ä¼˜åŒ–
- [ ] æ’°å†™æŠ€æœ¯åšå®¢ï¼Œæ€»ç»“ç»éªŒ

---

## å››ã€æ¨èå®æˆ˜é¡¹ç›®ï¼ˆç”±æ˜“åˆ°éš¾ï¼‰

### 1. AI èŠå¤©åŠ©æ‰‹ï¼ˆå…¥é—¨ï¼‰
**æ ¸å¿ƒæŠ€æœ¯**ï¼šLLM APIã€æµå¼å“åº”ã€å¯¹è¯å†å²
**æ—¶é—´**ï¼š1-2 å‘¨
```
åŠŸèƒ½ï¼š
- å¤šè½®å¯¹è¯
- å†å²è®°å½•
- è§’è‰²é¢„è®¾
- Markdown æ¸²æŸ“
```

### 2. æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆä¸­çº§ï¼‰
**æ ¸å¿ƒæŠ€æœ¯**ï¼šRAGã€Embeddingsã€å‘é‡æ•°æ®åº“
**æ—¶é—´**ï¼š2-3 å‘¨
```
åŠŸèƒ½ï¼š
- PDF/Markdown æ–‡æ¡£ä¸Šä¼ 
- è‡ªåŠ¨åˆ†å—å’Œç´¢å¼•
- è¯­ä¹‰æœç´¢
- æ¥æºå¼•ç”¨
```

### 3. AI ç¼–ç¨‹åŠ©æ‰‹ï¼ˆä¸­é«˜çº§ï¼‰
**æ ¸å¿ƒæŠ€æœ¯**ï¼šFunction Callingã€ä»£ç æ‰§è¡Œã€å¤šæ­¥æ¨ç†
**æ—¶é—´**ï¼š3-4 å‘¨
```
åŠŸèƒ½ï¼š
- ä»£ç ç”Ÿæˆ
- ä»£ç è§£é‡Š
- ä»£ç å®¡æŸ¥
- å•å…ƒæµ‹è¯•ç”Ÿæˆ
```

### 4. æ™ºèƒ½å®¢æœç³»ç»Ÿï¼ˆé«˜çº§ï¼‰
**æ ¸å¿ƒæŠ€æœ¯**ï¼šMulti-Agentã€å·¥ä½œæµç¼–æ’ã€çŸ¥è¯†åº“
**æ—¶é—´**ï¼š4-6 å‘¨
```
åŠŸèƒ½ï¼š
- æ„å›¾è¯†åˆ«
- å¤šè½®å¯¹è¯ç®¡ç†
- å·¥å•ç³»ç»Ÿé›†æˆ
- äººå·¥æ¥ç®¡
- æ»¡æ„åº¦è¯„ä¼°
```

### 5. AI æ¨¡æ‹Ÿé¢è¯•å®˜ï¼ˆé«˜çº§ï¼Œä½ çš„é¡¹ç›®ï¼ï¼‰
**æ ¸å¿ƒæŠ€æœ¯**ï¼šå¤æ‚ Promptã€åŠ¨æ€è¯„ä¼°ã€ä»£ç æ‰§è¡Œ
**æ—¶é—´**ï¼š6-8 å‘¨
```
åŠŸèƒ½ï¼š
- å²—ä½è‡ªå®šä¹‰
- åŠ¨æ€æé—®
- å®æ—¶ç¼–ç¨‹
- æ™ºèƒ½è¯„åˆ†
- å­¦ä¹ è·¯å¾„æ¨è
```

---

## äº”ã€å­¦ä¹ èµ„æºæ±‡æ€»

### å®˜æ–¹æ–‡æ¡£ï¼ˆå¿…è¯»ï¼‰
- ğŸŸ¢ Anthropic Claude APIï¼šhttps://docs.anthropic.com
- ğŸŸ¢ OpenAI Platformï¼šhttps://platform.openai.com/docs
- ğŸŸ¢ Vercel AI SDKï¼šhttps://sdk.vercel.ai/docs

### åœ¨çº¿è¯¾ç¨‹
- å´æ©è¾¾ã€ŠPrompt Engineeringã€‹ï¼šhttps://www.deeplearning.ai/short-courses/
- ã€ŠBuilding AI Applications with LangChainã€‹
- Fast.ai çš„å®ç”¨ AI è¯¾ç¨‹

### å¼€æºé¡¹ç›®ï¼ˆå­¦ä¹ æºç ï¼‰
- AutoGPTï¼šhttps://github.com/Significant-Gravitas/AutoGPT
- LangChainï¼šhttps://github.com/langchain-ai/langchainjs
- Vercel AI Chatbotï¼šhttps://github.com/vercel/ai-chatbot
- Quivrï¼ˆAI ç¬¬äºŒå¤§è„‘ï¼‰ï¼šhttps://github.com/QuivrHQ/quivr

### ä¹¦ç±
- ã€ŠDesigning Data-Intensive Applicationsã€‹ï¼ˆæ•°æ®å¯†é›†å‹åº”ç”¨ç³»ç»Ÿè®¾è®¡ï¼‰
- ã€ŠBuilding LLM Appsã€‹ï¼ˆ2024æ–°ä¹¦ï¼‰
- ã€ŠPrompt Engineering Guideã€‹ï¼ˆåœ¨çº¿å…è´¹ï¼‰

### ç¤¾åŒºå’Œåšå®¢
- Anthropic Blogï¼šhttps://www.anthropic.com/research
- OpenAI Cookbookï¼šhttps://cookbook.openai.com
- LangChain Blog
- Hugging Face Blog

### å®ç”¨å·¥å…·
- **Prompt æµ‹è¯•**ï¼š
  - Anthropic Consoleï¼šhttps://console.anthropic.com
  - OpenAI Playground

- **å‘é‡æ•°æ®åº“**ï¼š
  - Pineconeï¼ˆæ‰˜ç®¡ï¼‰
  - Weaviateï¼ˆå¼€æºï¼‰
  - Chromaï¼ˆè½»é‡çº§ï¼‰

- **ç›‘æ§å·¥å…·**ï¼š
  - LangSmithï¼ˆLangChain å®˜æ–¹ï¼‰
  - Heliconeï¼ˆAPI ç›‘æ§ï¼‰
  - Weights & Biasesï¼ˆå®éªŒè¿½è¸ªï¼‰

---

## å…­ã€å…³é”®å»ºè®®

### 1. å­¦ä¹ æ–¹æ³•
- **é¡¹ç›®é©±åŠ¨**ï¼šæ¯å­¦ä¸€ä¸ªæŠ€æœ¯ç‚¹ï¼Œç«‹å³ç”¨é¡¹ç›®å®è·µ
- **è¿­ä»£æ€ç»´**ï¼šå…ˆåšå‡º MVPï¼Œå†é€æ­¥ä¼˜åŒ–
- **é˜…è¯»æºç **ï¼šå­¦ä¹ ä¼˜ç§€å¼€æºé¡¹ç›®çš„æ¶æ„è®¾è®¡
- **å†™æŠ€æœ¯åšå®¢**ï¼šè¾“å‡ºå€’é€¼è¾“å…¥ï¼ŒåŠ æ·±ç†è§£

### 2. é¿å…çš„å‘
- âŒ ä¸è¦ä¸€å¼€å§‹å°±ç”¨ LangChain ç­‰æ¡†æ¶ï¼ˆå…ˆç†è§£åº•å±‚åŸç†ï¼‰
- âŒ ä¸è¦å¿½è§†æˆæœ¬æ§åˆ¶ï¼ˆLLM API å¾ˆè´µï¼‰
- âŒ ä¸è¦è¿‡åº¦è®¾è®¡ï¼ˆMVP åŸåˆ™ï¼‰
- âŒ ä¸è¦é—­é—¨é€ è½¦ï¼ˆå¤šçœ‹äº§å“ã€å¤šä½“éªŒï¼‰

### 3. èŒä¸šå‘å±•
- **æŠ€èƒ½ç»„åˆ**ï¼šå‰ç«¯ + AI + åç«¯ = å…¨æ ˆ AI å·¥ç¨‹å¸ˆ
- **å¸‚åœºéœ€æ±‚**ï¼š2026å¹´ AI Agent å¼€å‘æ˜¯æœ€çƒ­é—¨æ–¹å‘ä¹‹ä¸€
- **è–ªèµ„æ°´å¹³**ï¼šæŒæ¡ AI Agent å¼€å‘çš„å…¨æ ˆå·¥ç¨‹å¸ˆï¼Œè–ªèµ„å¯æå‡ 30-50%

### 4. æŒç»­å­¦ä¹ 
- å…³æ³¨ Anthropicã€OpenAI çš„æ–°åŠŸèƒ½å‘å¸ƒ
- å‚ä¸ AI å¼€å‘ç¤¾åŒºï¼ˆDiscordã€Redditï¼‰
- å°è¯•æ–°çš„ AI æ¨¡å‹å’Œå·¥å…·
- å…³æ³¨ AI Agent é¢†åŸŸçš„è®ºæ–‡

---

## ä¸ƒã€ä½ çš„ç¬¬ä¸€ä¸ªé¡¹ç›®ï¼šAI é¢è¯•å®˜

åŸºäºä½ å½“å‰çš„ llmops-ui é¡¹ç›®ï¼Œå»ºè®®çš„å¼€å‘æ­¥éª¤ï¼š

### Week 1-2ï¼šåŸºç¡€åŠŸèƒ½
- [ ] æ­å»ºåç«¯ APIï¼ˆExpress + TypeScriptï¼‰
- [ ] è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„ï¼ˆç”¨æˆ·ã€é¢è¯•ã€é—®é¢˜ï¼‰
- [ ] å®ç°ç”¨æˆ·ç™»å½•å’Œä¼šè¯ç®¡ç†
- [ ] å®Œæˆç¬¬ä¸€ä¸ªé¢è¯•å¯¹è¯ç•Œé¢

### Week 3-4ï¼šAI é›†æˆ
- [ ] é›†æˆ Claude API
- [ ] å®ç°å‰ç«¯å·¥ç¨‹å¸ˆ Prompt
- [ ] å®ŒæˆåŸºç¡€é—®ç­”åŠŸèƒ½
- [ ] æ·»åŠ æµå¼å“åº”

### Week 5-6ï¼šä»£ç ç¼–è¾‘å™¨
- [ ] é›†æˆ Monaco Editor
- [ ] å®ç°ä»£ç æ‰§è¡Œï¼ˆåç«¯æ²™ç®±ï¼‰
- [ ] æ·»åŠ ä»£ç è¯„å®¡åŠŸèƒ½

### Week 7-8ï¼šè¯„ä¼°ç³»ç»Ÿ
- [ ] å®ç°æ™ºèƒ½è¯„åˆ†
- [ ] ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
- [ ] æ•°æ®å¯è§†åŒ–ï¼ˆé›·è¾¾å›¾ï¼‰

### Week 9-10ï¼šä¼˜åŒ–ä¸ä¸Šçº¿
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] æ·»åŠ æ›´å¤šå²—ä½
- [ ] éƒ¨ç½²åˆ°äº‘å¹³å°
- [ ] æ”¶é›†ç”¨æˆ·åé¦ˆ

---

## æ€»ç»“

ä½œä¸ºå‰ç«¯å¼€å‘è€…ï¼Œä½ å·²ç»å…·å¤‡äº†å¾ˆå¥½çš„åŸºç¡€ã€‚å­¦ä¹  AI Agent å…¨æ ˆå¼€å‘çš„å…³é”®æ˜¯ï¼š

1. **æ‰å®æŒæ¡ Prompt Engineering**ï¼ˆè¿™æ˜¯æ ¸å¿ƒç«äº‰åŠ›ï¼‰
2. **è¡¥å……åç«¯å’Œæ•°æ®åº“çŸ¥è¯†**ï¼ˆæˆä¸ºçœŸæ­£çš„å…¨æ ˆï¼‰
3. **ç†è§£ AI Agent æ¶æ„æ¨¡å¼**ï¼ˆReActã€Plan-Executeï¼‰
4. **é€šè¿‡å®æˆ˜é¡¹ç›®å·©å›º**ï¼ˆè¾¹åšè¾¹å­¦ï¼‰
5. **æŒç»­å…³æ³¨æŠ€æœ¯å‰æ²¿**ï¼ˆAI é¢†åŸŸå‘å±•å¾ˆå¿«ï¼‰

é¢„è®¡ 16-18 å‘¨çš„ç³»ç»Ÿå­¦ä¹ ï¼Œä½ å°±èƒ½ç‹¬ç«‹å¼€å‘ç”Ÿäº§çº§çš„ AI Agent åº”ç”¨ã€‚

åŠ æ²¹ï¼AI æ—¶ä»£çš„å…¨æ ˆå·¥ç¨‹å¸ˆå‰æ™¯å¹¿é˜”ï¼ğŸš€
